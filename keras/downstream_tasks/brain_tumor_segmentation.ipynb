{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processed LIDC data can be found at: https://drive.google.com/drive/folders/1TLpPvR_9hfNdUbD9dFIXNpJ7m50VmD19?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from -r requirements.txt (line 5)) (4.50.2)\n",
      "Requirement already satisfied: sklearn in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from -r requirements.txt (line 6)) (0.0)\n",
      "Requirement already satisfied: scikit-image in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from -r requirements.txt (line 7)) (0.17.2)\n",
      "Requirement already satisfied: simpleitk in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from -r requirements.txt (line 8)) (2.0.1)\n",
      "Requirement already satisfied: scipy in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from -r requirements.txt (line 9)) (1.5.2)\n",
      "Requirement already satisfied: matplotlib in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from -r requirements.txt (line 10)) (3.3.2)\n",
      "Collecting tensorflow-gpu==1.14.0\n",
      "  Downloading tensorflow_gpu-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (377.0 MB)\n",
      "\u001B[K     |████████████████████████████████| 377.0 MB 45 kB/s s eta 0:00:01   |▉                               | 10.4 MB 5.2 MB/s eta 0:01:11     |█▏                              | 13.4 MB 5.2 MB/s eta 0:01:11     |██████████████████▎             | 215.1 MB 52.8 MB/s eta 0:00:04     |███████████████████▏            | 226.2 MB 52.8 MB/s eta 0:00:03     |██████████████████████████▎     | 310.2 MB 60.9 MB/s eta 0:00:02\n",
      "\u001B[?25hRequirement already satisfied: keras==2.2.4 in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from -r requirements.txt (line 13)) (2.2.4)\n",
      "Collecting torch==1.3.1\n",
      "  Downloading torch-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (734.6 MB)\n",
      "\u001B[K     |████████████████████████████████| 734.6 MB 41 kB/s s eta 0:00:01     |██████████████                  | 319.8 MB 42.8 MB/s eta 0:00:10     |███████████████████████▉        | 547.5 MB 62.0 MB/s eta 0:00:04\n",
      "\u001B[?25hCollecting torchsummary\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Requirement already satisfied: scikit-learn in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from sklearn->-r requirements.txt (line 6)) (0.23.2)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from scikit-image->-r requirements.txt (line 7)) (2020.9.3)\n",
      "Requirement already satisfied: networkx>=2.0 in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from scikit-image->-r requirements.txt (line 7)) (2.5)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from scikit-image->-r requirements.txt (line 7)) (8.0.0)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from scikit-image->-r requirements.txt (line 7)) (2.9.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from scikit-image->-r requirements.txt (line 7)) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.15.1 in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from scikit-image->-r requirements.txt (line 7)) (1.19.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 10)) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 10)) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 10)) (2020.6.20)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 10)) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 10)) (2.8.1)\n",
      "Collecting wrapt>=1.11.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0->-r requirements.txt (line 12)) (3.13.0)\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
      "  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
      "\u001B[K     |████████████████████████████████| 488 kB 33.8 MB/s eta 0:00:01\n",
      "\u001B[?25hRequirement already satisfied: gast>=0.2.0 in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0->-r requirements.txt (line 12)) (0.4.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0->-r requirements.txt (line 12)) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0->-r requirements.txt (line 12)) (1.31.0)\n",
      "Collecting google-pasta>=0.1.6\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001B[K     |████████████████████████████████| 57 kB 10.2 MB/s eta 0:00:01\n",
      "\u001B[?25hRequirement already satisfied: keras-applications>=1.0.6 in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0->-r requirements.txt (line 12)) (1.0.8)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0->-r requirements.txt (line 12)) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0->-r requirements.txt (line 12)) (1.1.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0->-r requirements.txt (line 12)) (0.8.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0->-r requirements.txt (line 12)) (0.35.1)\n",
      "Collecting tensorboard<1.15.0,>=1.14.0\n",
      "  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
      "\u001B[K     |████████████████████████████████| 3.1 MB 52.9 MB/s eta 0:00:01\n",
      "\u001B[?25hRequirement already satisfied: absl-py>=0.7.0 in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0->-r requirements.txt (line 12)) (0.10.0)\n",
      "Requirement already satisfied: pyyaml in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from keras==2.2.4->-r requirements.txt (line 13)) (5.3.1)\n",
      "Requirement already satisfied: h5py in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from keras==2.2.4->-r requirements.txt (line 13)) (2.10.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from scikit-learn->sklearn->-r requirements.txt (line 6)) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from scikit-learn->sklearn->-r requirements.txt (line 6)) (0.17.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from networkx>=2.0->scikit-image->-r requirements.txt (line 7)) (4.4.2)\n",
      "Requirement already satisfied: setuptools in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow-gpu==1.14.0->-r requirements.txt (line 12)) (50.3.0.post20201006)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0->-r requirements.txt (line 12)) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0->-r requirements.txt (line 12)) (3.3.2)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0->-r requirements.txt (line 12)) (2.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/zongwei/miniconda3/envs/mask3/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0->-r requirements.txt (line 12)) (3.3.1)\n",
      "Building wheels for collected packages: wrapt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for wrapt (setup.py) ... \u001B[?25ldone\n",
      "\u001B[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=66149 sha256=57da50aebfd5c80a897443f54fbae2c12d0a65019eb44be85f95e6cd2d9a7e93\n",
      "  Stored in directory: /home/zongwei/.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\n",
      "Successfully built wrapt\n",
      "Installing collected packages: wrapt, tensorflow-estimator, google-pasta, tensorboard, tensorflow-gpu, torch, torchsummary\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 1.13.0\n",
      "    Uninstalling tensorflow-estimator-1.13.0:\n",
      "      Successfully uninstalled tensorflow-estimator-1.13.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 1.13.1\n",
      "    Uninstalling tensorboard-1.13.1:\n",
      "      Successfully uninstalled tensorboard-1.13.1\n",
      "\u001B[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "tensorflow 1.13.1 requires tensorboard<1.14.0,>=1.13.0, but you'll have tensorboard 1.14.0 which is incompatible.\n",
      "tensorflow 1.13.1 requires tensorflow-estimator<1.14.0rc0,>=1.13.0, but you'll have tensorflow-estimator 1.14.0 which is incompatible.\u001B[0m\n",
      "Successfully installed google-pasta-0.2.0 tensorboard-1.14.0 tensorflow-estimator-1.14.0 tensorflow-gpu-1.14.0 torch-1.3.1 torchsummary-1.5.1 wrapt-1.12.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T14:59:21.772255104Z",
     "start_time": "2023-11-20T14:59:20.296187550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras = 2.2.4-tf\n",
      "tensorflow-gpu = 1.14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "from __future__ import print_function\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}\n",
    "import tensorflow as tf\n",
    "print(\"keras = {}\".format(tf.keras.__version__))\n",
    "print(\"tensorflow-gpu = {}\".format(tf.__version__))\n",
    "try:\n",
    "    tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "except:\n",
    "    pass\n",
    "import random\n",
    "import shutil\n",
    "import argparse\n",
    "import sklearn\n",
    "from pathlib import Path\n",
    "from utils import *\n",
    "from unet3d import *\n",
    "from config import *\n",
    "import BraTS\n",
    "\n",
    "class set_args():\n",
    "    gpu = 0\n",
    "    data = None\n",
    "    apps = 'bms'\n",
    "    run = 1\n",
    "    cv = None\n",
    "    subsetting = None\n",
    "    suffix = 'random'\n",
    "    task = 'segmentation'\n",
    "    \n",
    "args = set_args()\n",
    "\n",
    "if args.gpu is not None:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu)\n",
    "\n",
    "conf = bms_config(args)\n",
    "\n",
    "# If keras error just reinstall it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T15:12:01.856253792Z",
     "start_time": "2023-11-20T15:12:01.465917574Z"
    }
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 75.8 GiB for an array with shape (285, 4, 240, 240, 155) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_15000/1855605874.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m     \u001B[0mbrats_root\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'/home/ioanna/PycharmProjects/uva-thesis/data'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m     year=2017)\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0mx_train\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_load_images\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_train\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmris\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx_train\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msegs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/ModelsGenesis/keras/downstream_tasks/BraTS/DataSet.py\u001B[0m in \u001B[0;36m_load_images\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     78\u001B[0m         \u001B[0msegs_shape\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_patients\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mimage_shape\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     79\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 80\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_mris\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mempty\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmris_shape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     81\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_segs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mempty\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msegs_shape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     82\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mMemoryError\u001B[0m: Unable to allocate 75.8 GiB for an array with shape (285, 4, 240, 240, 155) and data type float64"
     ]
    }
   ],
   "source": [
    "dataset = BraTS.DataSet(\n",
    "    brats_root='/home/ioanna/PycharmProjects/uva-thesis/data',\n",
    "    year=2017)\n",
    "x_train = dataset.train\n",
    "\n",
    "lol = x_train._mris[2]\n",
    "\n",
    "print(x_train.mris.shape, x_train.segs.shape)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train.subset(['Brats17_TCIA_630_1']).mris[:,1,:,:,90].squeeze())\n",
    "\n",
    "# x_train, y_train = load_image(conf, 'train')\n",
    "# print('x_train: {} | {} ~ {}'.format(x_train.shape, np.min(x_train), np.max(x_train)))\n",
    "# print('y_train: {} | {} ~ {}'.format(y_train.shape, np.min(y_train), np.max(y_train)))\n",
    "# \n",
    "# x_valid, y_valid = load_image(conf, 'valid')\n",
    "# print('x_valid: {} | {} ~ {}'.format(x_valid.shape, np.min(x_valid), np.max(x_valid)))\n",
    "# print('y_valid: {} | {} ~ {}'.format(y_valid.shape, np.min(y_valid), np.max(y_valid)))\n",
    "# \n",
    "# x_test, y_test = load_image(conf, 'test')\n",
    "# print('x_test: {} | {} ~ {}'.format(x_test.shape, np.min(x_test), np.max(x_test)))\n",
    "# print('y_test: {} | {} ~ {}'.format(y_test.shape, np.min(y_test), np.max(y_test)))import tensorflow.keras as keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune Models Genesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.suffix = 'genesis'\n",
    "conf = bms_config(args)\n",
    "conf.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(1)\n",
    "model = unet_model_3d((1,conf.input_rows,conf.input_cols,conf.input_deps), batch_normalization=True)\n",
    "if conf.weights is not None:\n",
    "    print(\"[INFO] Load pre-trained weights from {}\".format(conf.weights))\n",
    "    model.load_weights(conf.weights)\n",
    "print(2)\n",
    "model, callbacks = model_setup(model, conf, task=args.task)\n",
    "print(3)\n",
    "while conf.batch_size > 1:\n",
    "    # To find a largest batch size that can be fit into GPU\n",
    "    print(conf.batch_size)\n",
    "    try:\n",
    "        model.fit_generator(x_train, y_train,\n",
    "                  validation_data=(x_valid, y_valid),\n",
    "                  batch_size=conf.batch_size,\n",
    "                  epochs=conf.nb_epoch, \n",
    "                  verbose=conf.verbose, \n",
    "                  shuffle=True,\n",
    "                  callbacks=callbacks)\n",
    "        break\n",
    "    except tf.errors.ResourceExhaustedError as e:\n",
    "        conf.batch_size = int(conf.batch_size - 2)\n",
    "        print(\"\\n> Batch size = {}\".format(conf.batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet_model_3d((1,conf.input_rows,conf.input_cols,conf.input_deps), batch_normalization=True)\n",
    "print(\"[INFO] Load trained model from {}\".format( os.path.join(conf.model_path, conf.exp_name+\".h5\") ))\n",
    "model.load_weights( os.path.join(conf.model_path, conf.exp_name+\".h5\") )\n",
    "\n",
    "p_test = segmentation_model_evaluation(model=model, config=conf, x=x_test, y=y_test, note=conf.exp_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_test = np.squeeze(p_test)\n",
    "for i in range(0, x_test.shape[0], 80):\n",
    "    plot_image_truth_prediction(x_test[i], y_test[i], p_test[i], rows=5, cols=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.suffix = 'random'\n",
    "conf = ncs_config(args)\n",
    "conf.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet_model_3d((1,conf.input_rows,conf.input_cols,conf.input_deps), batch_normalization=True)\n",
    "if conf.weights is not None:\n",
    "    print(\"[INFO] Load pre-trained weights from {}\".format(conf.weights))\n",
    "    model.load_weights(conf.weights)\n",
    "model, callbacks = model_setup(model, conf, task=args.task)\n",
    "\n",
    "while conf.batch_size > 1:\n",
    "    # To find a largest batch size that can be fit into GPU\n",
    "    try:\n",
    "        model.fit(x_train, y_train,\n",
    "                  validation_data=(x_valid, y_valid),\n",
    "                  batch_size=conf.batch_size,\n",
    "                  epochs=conf.nb_epoch, \n",
    "                  verbose=conf.verbose, \n",
    "                  shuffle=True,\n",
    "                  callbacks=callbacks)\n",
    "        break\n",
    "    except tf.errors.ResourceExhaustedError as e:\n",
    "        conf.batch_size = int(conf.batch_size - 2)\n",
    "        print(\"\\n> Batch size = {}\".format(conf.batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet_model_3d((1,conf.input_rows,conf.input_cols,conf.input_deps), batch_normalization=True)\n",
    "print(\"[INFO] Load trained model from {}\".format( os.path.join(conf.model_path, conf.exp_name+\".h5\") ))\n",
    "model.load_weights( os.path.join(conf.model_path, conf.exp_name+\".h5\") )\n",
    "\n",
    "p_test = segmentation_model_evaluation(model=model, config=conf, x=x_test, y=y_test, note=conf.exp_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_test = np.squeeze(p_test)\n",
    "for i in range(0, x_test.shape[0], 80):\n",
    "    plot_image_truth_prediction(x_test[i], y_test[i], p_test[i], rows=5, cols=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
